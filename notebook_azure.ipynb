{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, Dense, Embedding, Dropout, Flatten\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1639340945767
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real = pd.read_csv('./data/True.csv')\n",
        "fake = pd.read_csv('./data/Fake.csv')"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1639340948759
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real['type'] = 1"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1639340949227
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake['type'] = 0"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1639340949694
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = pd.concat([real, fake])"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1639340950089
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(all_data))\n",
        "print(len(all_data[all_data.date.str.contains('\\w+ \\d{1,}, \\d{4}') | all_data.date.str.contains('\\d{2}-\\w{3}-\\d{2}') ]))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "44898\n44888\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1639340950437
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All Subjects are exclusive to either Fake news or Real news no intersection"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "all_data[(all_data['subject'] == 'Government News') & (all_data['type']==True)].head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "Empty DataFrame\nColumns: [title, text, subject, date, type]\nIndex: []",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1639340950780
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = all_data.drop(['title','subject'],axis=1)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1639340951079
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sort data in terms in ascending date"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "## the date columns occasionally have random values such as a article url or the article title so we are just enforcing that the date is normal and parseable through some regex\n",
        "all_data =  all_data[all_data.date.str.contains('\\w+ \\d{1,}, \\d{4}') | all_data.date.str.contains('\\d{2}-\\w{3}-\\d{2}') ]\n",
        "\n",
        "# Converting the date into datetime so it can be easily sorted\n",
        "all_data['date']= pd.to_datetime(all_data['date'])\n",
        "all_data.sort_values(by = 'date', inplace = True)\n"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1639340951870
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## First and last date\n",
        "print(all_data.iloc[0].date)\n",
        "print(all_data.iloc[-1].date)\n",
        "print(len(all_data))\n",
        "print(len(all_data[all_data.type == True]))\n",
        "print(len(all_data[all_data.type == False]))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2015-03-31 00:00:00\n2018-02-19 00:00:00\n44888\n21417\n23471\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1639340952347
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Here we are removing stop words from the text column of the rows we are removing them to remove aribitrary common words that occur in human language that dont really provide any value to the model this is also a good tradeoff to cut down on training time, Depending on intial results we may want to keep the stopwords in or edit the list of stopwords, this would be a case where the stopwords are consistently providing context to the articles and we dont want to remove them."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639340953981
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopW = stopwords.words('english')\n",
        "all_data['text'] = all_data['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopW)]))"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1639340988418
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Here we are doing a technique called lemmitization which basically maps words that have the same meaning to a single word (the root form found in a Lemma) that still conveys same meaning. \n",
        "Examples\n",
        "- Phone, Cell, SmartPhone -> Phone\n",
        "- Hungry, starved -> Famished \n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "nltk\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "all_data['lemmatized'] = all_data['text'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1639341026273
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = all_data.type.tolist()\n",
        "corpus = all_data['lemmatized'].tolist()"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1639341026623
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_devices('GPU')\r\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\r\n",
        "print(gpus)\r\n",
        "tf.config.set_visible_devices(gpus[0], 'GPU') # unhide potentially hidden GPU\r\n",
        "tf.config.get_visible_devices()\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639341026939
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voc_size = 10000\n",
        "vector_length = 5000\n",
        "onehot_repr = [one_hot(words,voc_size) for words in corpus]\n",
        "embedded_docs = pad_sequences(onehot_repr,padding='pre',maxlen=vector_length)\n",
        "print(embedded_docs.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(44888, 5000)\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1639341034379
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Og model \n",
        "#Creating the lstm model\n",
        "embedding_vector_features=64\n",
        "es = EarlyStopping(monitor='val_loss',mode='min')\n",
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,embedding_vector_features,input_length=vector_length))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(LSTM(100,return_sequences=True))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "#Compiling the model\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding_1 (Embedding)     (None, 5000, 64)          640000    \n                                                                 \n dropout_3 (Dropout)         (None, 5000, 64)          0         \n                                                                 \n lstm_2 (LSTM)               (None, 5000, 100)         66000     \n                                                                 \n dropout_4 (Dropout)         (None, 5000, 100)         0         \n                                                                 \n lstm_3 (LSTM)               (None, 100)               80400     \n                                                                 \n dropout_5 (Dropout)         (None, 100)               0         \n                                                                 \n flatten (Flatten)           (None, 100)               0         \n                                                                 \n dense_1 (Dense)             (None, 64)                6464      \n                                                                 \n dense_2 (Dense)             (None, 1)                 65        \n                                                                 \n=================================================================\nTotal params: 792,929\nTrainable params: 792,929\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
        }
      ],
      "execution_count": 60,
      "metadata": {
        "gather": {
          "logged": 1639344525565
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the lstm model\r\n",
        "embedding_vector_features=24\r\n",
        "es = EarlyStopping(monitor='val_loss',mode='min')\r\n",
        "model=Sequential()\r\n",
        "model.add(Embedding(voc_size,embedding_vector_features,input_length=vector_length))\r\n",
        "model.add(Dropout(0.8))\r\n",
        "model.add(LSTM(10,return_sequences=True))\r\n",
        "model.add(Dropout(0.6))\r\n",
        "model.add(LSTM(10))\r\n",
        "model.add(Dropout(0.8))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(64,activation='relu'))\r\n",
        "model.add(Dense(1,activation='sigmoid'))\r\n",
        "\r\n",
        "#Compiling the model\r\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\r\n",
        "print(model.summary())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model: \"sequential_8\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding_8 (Embedding)     (None, 5000, 24)          240000    \n                                                                 \n dropout_24 (Dropout)        (None, 5000, 24)          0         \n                                                                 \n lstm_16 (LSTM)              (None, 5000, 10)          1400      \n                                                                 \n dropout_25 (Dropout)        (None, 5000, 10)          0         \n                                                                 \n lstm_17 (LSTM)              (None, 10)                840       \n                                                                 \n dropout_26 (Dropout)        (None, 10)                0         \n                                                                 \n flatten_7 (Flatten)         (None, 10)                0         \n                                                                 \n dense_15 (Dense)            (None, 64)                704       \n                                                                 \n dense_16 (Dense)            (None, 1)                 65        \n                                                                 \n=================================================================\nTotal params: 243,009\nTrainable params: 243,009\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
        }
      ],
      "execution_count": 128,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639359204385
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rougly 2 years worth of data and 31437 data points and a near even split of fake and real news"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "# Converting the X and y as array\n",
        "X_final=np.array(embedded_docs)\n",
        "y_final=np.array(y)\n",
        "\n",
        "#Check shape of X and y final\n",
        "X_final.shape,y_final.shape\n",
        "\n",
        "# Train test split of the X and y final\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.20, random_state=42)\n",
        "Y_validation = y_test[0:1000]\n",
        "X_validation = X_test[0:1000]\n",
        "y_test = y_test[1000:]\n",
        "X_test = X_test[1000:]\n",
        "# Fitting with 10 epochs and 64 batch size\n",
        "model.fit(X_train,y_train,validation_data=(X_validation,Y_validation),epochs=10,batch_size=batch_size,verbose=1,callbacks=[es])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/10\n141/141 [==============================] - 112s 776ms/step - loss: 0.4575 - accuracy: 0.7514 - val_loss: 0.1050 - val_accuracy: 0.9670\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/10\n141/141 [==============================] - 109s 770ms/step - loss: 0.1763 - accuracy: 0.9203 - val_loss: 0.0654 - val_accuracy: 0.9780\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 129,
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7efec3edd8e0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 129,
      "metadata": {
        "gather": {
          "logged": 1639359430559
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=(model.predict(X_test) > 0.5).astype(\"int32\")\r\n"
      ],
      "outputs": [],
      "execution_count": 130,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639360013284
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# classes_x=model.predict>0.5.astype('int32')\r\n",
        "#print(np.unique(X_test))\r\n",
        "# print(y_pred)\r\n",
        "print(accuracy_score(y_test,y_pred))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0.9873401855101529\n"
        }
      ],
      "execution_count": 131,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639360094072
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We must save our model so we can use it for making practical predictions. We must extract the preprocessing that we did for the training data so it's easy to input actual data so we will put all of that into a function"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Model\r\n",
        "# model.save('models/third_model')\r\n",
        "# model.save('models/third_model_dropout_relu.h5')\r\n",
        "# loaded_model = tf.keras.models.load_model('models/third_model_dropout_relu.h5')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\nINFO:tensorflow:Assets written to: models/third_model/assets\nWARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7eff1db54190> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\nWARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7eff1d89a0a0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "INFO:tensorflow:Assets written to: models/third_model/assets\n"
        }
      ],
      "execution_count": 64,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639345427410
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 5000, 64)          640000    \n                                                                 \n dropout (Dropout)           (None, 5000, 64)          0         \n                                                                 \n lstm (LSTM)                 (None, 5000, 100)         66000     \n                                                                 \n dropout_1 (Dropout)         (None, 5000, 100)         0         \n                                                                 \n lstm_1 (LSTM)               (None, 100)               80400     \n                                                                 \n dropout_2 (Dropout)         (None, 100)               0         \n                                                                 \n dense (Dense)               (None, 1)                 101       \n                                                                 \n=================================================================\nTotal params: 786,501\nTrainable params: 786,501\nNon-trainable params: 0\n_________________________________________________________________\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639342310057
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_article(article,trained_model=model):\r\n",
        "    \r\n",
        "    voc_size = 10000\r\n",
        "    vector_length = 5000\r\n",
        "    \r\n",
        "    ## Clean the article\r\n",
        "    stopW = stopwords.words('english')\r\n",
        "    cleaned_1 = ' '.join([article])\r\n",
        "    cleaned_2 = ' '.join([lemmatizer.lemmatize(word) for word in cleaned_1.split()])\r\n",
        "    encoded = one_hot(cleaned_2,voc_size)\r\n",
        "    embedded_doc = pad_sequences([encoded],padding='pre',maxlen=vector_length)\r\n",
        "    #y_pred=(model.predict(X_test) > 0.5).astype(\"int32\")\r\n",
        "    return trained_model.predict([embedded_doc])# > 0.5).astype(\"int32\")\r\n"
      ],
      "outputs": [],
      "execution_count": 132,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639360105612
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake_1 = all_data[all_data['type']==1].iloc[0:100]['text'].tolist()"
      ],
      "outputs": [],
      "execution_count": 133,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639360110485
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now lets try Using this model with articles I've pulled through the internet\r\n",
        "### The training dataset typically consisted of polictal and world news \r\n",
        "### For real data I've decided to use a variety of sources both that play to the bias of the dataset and other sources like tech,crypto,videogame, and sports aswell as satire news sources\r\n",
        "### Becasue we thought the results could be interesting because the satire typically takes inspiration from the obsurdity of real events.\r\n",
        "- The Onion\r\n",
        "- The beaverton\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "real_world = {\r\n",
        "'beaver' : f'''BATTLE CREEK, MI – Kellogg’s is moving to replace the 1,400 striking workers at several major US plants after contract negotiations broke down earlier this week. Hoping to stamp out any further dissension, Kellogg’s has also announced that several other employees who engaged in ‘acts of solidarity’ will also be replaced. Notable among them, Tony the Tiger of Frosted Flakes fame.\r\n",
        "\r\n",
        "Despite his imminent dismissal, the cartoon spokestiger has only grown more outspoken on the topic of worker’s rights. Speaking at a rally on Friday, he addressed BCTGM union members.\r\n",
        "\r\n",
        "“I can’t believe they’d treat their employees this poorly”, Tony said, his trademark red neckerchief defiantly covering his face. “These are same employees who worked g-r-rueling 80-hour work weeks to keep these plants open at the height of the pandemic. Would it kill them to show a little g-r-ratitiude?”\r\n",
        "\r\n",
        "“This whole thing just stinks of corporate g-r-reed. Kellogg’s made $4 billion in profit this year and where does it go? Into the pockets of money-gr-r-rubbing CEOs. God, those gr-r-easy bastards gr-r-rind my gears to no end!”, he added to cheers from the crowd. \r\n",
        "\r\n",
        "Replacing Tony will be Kellogg’s new scab mascot Jerry the Jaguar. Jerry, a cartoon jaguar rendered in MS Paint by non-union artists and voiced by voice actors found on Fiverr. Jerry will soon be “spotted” on boxes of Frosted Flakes at grocery stores across the country sporting his signature green bandana and a tongue slightly too big for his mouth; reminding children everywhere that they’re not just good,  “they’re gr-r-fine.”\r\n",
        "\r\n",
        "A relative unknown in the breakfast mascot industry; Jerry’s only previous work, according to his IMDB page, was representing a now-discontinued breakfast cereal called “Corn Shapes.”\r\n",
        "\r\n",
        "“Look, Kellogg’s loves Tony and we wish him nothing but the best in his future endeavors,” said spokesperson Donna Winters at a publicity event for Jerry the Jaguar. “But his message of kindness, fair-play, and sportsmanship just doesn’t resonate with the Kellogg’s brand anymore. Besides, we think the kids are really going to respond well to Jerry and his message of ‘taking what you can get’ and ‘keeping your head down.”\r\n",
        "\r\n",
        "At press time, a truly shocking amount of pornographic furry art featuring Jerry the Jaguar had been posted on the internet.''',\r\n",
        "\r\n",
        "'cnn' : f'''Former White House trade adviser Peter Navarro has refused to comply with a Congressional subpoena for documents related to the Trump administration's response to the coronavirus, saying the former president ordered him not to, according to a letter Navarro wrote to the subcommittee investigating.\r\n",
        "Navarro served as one of former President Donald Trump's pandemic response advisers and was, in part, responsible for curating the response to the virus. CNN previously reported he warned the White House in a January 2020 memo the virus could become a \"full-blown pandemic.\"\r\n",
        "The House Select Subcommittee on the Coronavirus Crisis issued the subpoena last month as part of its probe into the federal response to the pandemic, originally requesting Navarro provide documents by December 8 and a deposition on December 15.\r\n",
        "\r\n",
        "Defying the request for documents Navarro wrote in a letter on December 7, \"It is a direct order that I should not comply with the subpoena.\"\r\n",
        "\r\n",
        "The subcommittee has still given Navarro until December 15 to sit for a deposition and demanded again Saturday he turn over relevant documents.\r\n",
        "\r\n",
        "Navarro said in his letter to the subcommittee -- and addressed the letter to \"Representative Rayburn\" -- he would not cooperate because Trump told him to \"protect executive privilege.\"\r\n",
        "Navarro presumably intended to address the letter to Rep. James Clyburn, a Democrat and chairman of the coronavirus crisis panel. The subcommittee resides in the Rayburn House Office Building.\r\n",
        "\r\n",
        "The Washington Post first reported on the refusal.\r\n",
        "Clyburn responded in a letter to Navarro he had no valid basis for refusing to comply and he had waived any privilege by writing about conversations with Trump on the coronavirus response.\r\n",
        "The refusal is \"particularly indefensible given that you disclosed many details about your work in the White House, including details of conversations with the former President about the pandemic response, in your recent book and related press tour,\" Clyburn said in a letter to Navarro on Saturday.\r\n",
        "Failing to comply with a subpoena can put a potential witness in contempt of Congress, which can lead to escalating financial penalties and the possibility of jail time.\r\n",
        "One of Trump's former advisers, Steve Bannon, was indicted for contempt of Congress last month over his refusal to testify to the committee investigating the January 6 attack on the Capitol.\r\n",
        "Navarro could not be immediately reached for a response to Clyburn's letter.\r\n",
        "\r\n",
        "In a statement, Trump confirmed he asked Navarro not to cooperate.\r\n",
        "\"The Communist Democrats are engaging in yet another Witch Hunt, this time going after my Administration's unprecedented and incredible coronavirus response, despite the fact that, sadly, more Americans have died this year from Covid than in all of 2020,\" he said in a statement. \"It is a Witch Hunt ... I'm telling Peter Navarro to protect executive privilege and not let these unhinged Democrats discredit our great accomplishments. The Witch Hunts must end!\"''',\r\n",
        "'cnn2' : f'''Connecticut man John Griffin was arrested Friday and charged with three counts of using a facility of interstate commerce to attempt to entice minors to engage in unlawful sexual activity, the United States Attorney's Office for the District of Vermont said in a news release.\r\n",
        "Griffin, 44, has been a producer with CNN for about eight years.\r\n",
        "\"The charges against Mr. Griffin are deeply disturbing,\" a spokesperson for the network said in a statement Saturday. \"We only learned of his arrest yesterday afternoon and have suspended him pending investigation.\"\r\n",
        "\r\n",
        "The charges stem from conversations between Griffin and the purported parents of minor daughters, in which he allegedly tried to persuade them to \"allow him to train their daughters to be sexually submissive,\" as well as an incident in which prosecutors allege unlawful sexual activity occurred with a 9-year-old girl, the news release said.\r\n",
        "\r\n",
        "CNN has not been able to identify an attorney for Griffin.\r\n",
        "\r\n",
        "According to an indictment filed on Thursday, Griffin allegedly paid for and kept an online profile on a \"BDSM dating, Fetish, and Kink Site\" for several years leading up to July 2020, on which he allegedly wrote he was looking for women who were \"sexually 'submissive' and 'open-minded.'\"\r\n",
        "During conversations on separate online platforms, Griffin allegedly said he believed in \"a way of life\" in which \"women are sexually subservient and inferior to men,\" according to the indictment. He allegedly used online platforms to seek parents \"who would allow him to train their minor daughters to be sexually subservient,\" the indictment said.\r\n",
        "Around February 2020, Griffin allegedly acquired a Vermont ski house in which he offered to host mothers and their minor daughters for \"sexual training\" purposes, according to the indictment.\r\n",
        "Between April and June 2020, prosecutors allege Griffin talked online with the purported father of a 14-year-old girl and separately, the mother of a 16-year-old girl, proposing they begin \"sexual training,\" the indictment said.\r\n",
        "In June and July, Griffin also allegedly talked online and on the phone with someone who claimed to be the mother of two girls, 9 and 13, according to the indictment.\r\n",
        "Griffin allegedly paid more than $3,000 to the woman to fly her and the 9-year-old girl to Boston in July, where prosecutors say he picked them up from the airport and brought them to the ski house \"where the child was directed to engage in and did engage in illegal sexual activity,\" the indictment said.\r\n",
        "\r\n",
        "\"The allegations are deeply disturbing, and our office is committed to working with our partners at the United States Attorney's Office District of Vermont to ensure Mr. Griffin is held accountable for his actions,\" the FBI said in a statement posted on Twitter Friday. \"The FBI, along with our law enforcement partners, will continue to aggressively investigate those who victimize the most vulnerable in our communities.\"\r\n",
        "If convicted, Griffin faces anywhere from 10 years in prison to a life sentence for each count, according to the news release.''',\r\n",
        "'gwpundit' : '''Florida – New jailhouse documents obtained by Fox News reveal 39-year-old Semmie Williams likely murdered 14-year-old Ryan Rogers because of anti-white racism.\r\n",
        "\r\n",
        "Williams was arrested in Miami late last month after he fatally stabbed Rogers near an overpass on November 15.\r\n",
        "\r\n",
        "The teen boy was stabbed “numerous times in the head and face,” according to the police report.\r\n",
        "\r\n",
        "Palm Beach Gardens Police Chief initially said the murder was a “random act.\r\n",
        "Newly released records show Williams used anti-white racial slurs after he was arrested and booked.\r\n",
        "\r\n",
        "Williams also appeared to admit he murdered the boy because of what whites did to blacks in the past.\r\n",
        "\r\n",
        "“While fingerprinting his left hand, I asked him if he understood the charges,” Officer Michael McCabe wrote in an incident report. “He stated, ‘Yea, murder, because of what they did to Black people about giving them syphilis.'”\r\n",
        "\r\n",
        "Williams called one of the police officers “white devil” after he tried to break free from the officer.\r\n",
        "\r\n",
        "Read the jailhouse records here:”''',\r\n",
        "\r\n",
        "'onion':f'''WASHINGTON—In an effort to educate the opposition party on the true value of civic engagement, congressional Democrats staged an elaborate 4th of July pageant Friday in an effort to teach their Republican colleagues the importance of democracy.\r\n",
        "\r\n",
        "Sources confirmed that the four-hour “star-spangled spectacular,” which involved months of preparation headed up by Senate Majority Leader Chuck Schumer, provided one blow-out night of freedom, fun, and refreshments. The Independence Day pageant, staged for the benefit of Congressional Republicans to promote consensus-building and working together, reportedly featured a variety of songs, dances, and skits from Democratic representatives tied to the loose theme of “America The Beautiful.”\r\n",
        "\r\n",
        "“The Republicans refuse to accept the majesty and preciousness of our democracy, and so we have no choice but to offer them this no-holds-barred, musical extravaganza,” said Senate Majority Leader Chuck Schumer (D-NY), pointing to a scene in which Tim Kaine (D-VA) donned a dress and bonnet to portray Susan B. Anthony as well as members of the Oversight and Reform Committee filing into the auditorium playing “Yankee Doodle Dandy” on the recorder as particularly uplifting moments that helped convey the responsibility of honorably serving your constituents. “We’ve been rehearsing for months, learning choreography, and researching our state’s foods and traditions to really show how amazing this country can be, and our hope is that everybody who sees the show is going to come away feeling the weight of history on their shoulders, as well as humming a few classic patriotic tunes.”\r\n",
        "\r\n",
        "“It is not hyperbole to say that our nation is on the precipice of disaster,” continued Schumer. “So, we’ve been pulling out all the stops to make sure that every performance really dazzles.”\r\n",
        "Several eyewitness accounts revealed that the pageant featured involvement from every Democratic legislator except Joe Manchin (D-WV) who refused to participate if there were no Republican performers present. The patriotic program also included Sen. Ed Markey (D-MA) proudly marching in place while singing “My Country ’Tis Of Thee” and House Speaker Nancy Pelosi wearing a homemade Statue of Liberty costume and twirling on the stage with American flag handkerchiefs.\r\n",
        "\r\n",
        "Attendees confirmed that the show concluded with a lively, heartfelt climax in which the entire caucus held up sparklers while singing a medley including “This Land Is Your Land” and “You’re A Grand Old Flag,” adding that despite a few minor flubs, such as Sen. Bernie Sanders (I-VT) struggling for several minutes to light a cigarette while playing FDR and Sen. Dianne Feinstein (D-CA) forgetting her line about California’s main exports and running offstage crying, it was a generally enjoyable event.\r\n",
        "\r\n",
        "According to sources, several Democrats expressed disappointment that no Republican officials had chosen to attend apart from Sen. Rand Paul (R-KY), who reportedly only stayed long enough to fill a plate with red-white-and-blue sugar cookies before quickly exiting.\r\n",
        "\r\n",
        "“I can’t believe they learned all those lines,” said Heather Fenton, mother of Sen. Jon Ossoff (D-GA), confirming that she had gotten some priceless footage of her son and his friends in their “absolutely adorable” outfits. “I’ll admit, the speaker system was pretty spotty so you couldn’t always hear what they were saying, and the A/C stopped working halfway through so I stepped out for about half an hour, but you could really see all the hard work they put into this, and I just couldn’t be more proud of them.” \r\n",
        "“I’m not sure anyone who wasn’t a friend or family member would have enjoyed it,” Fenton continued. “But it made them feel like they could make a difference, and that’s the most important thing.” ''',\r\n",
        "'the_verge' : f'''Former Apple employee Cher Scarlett says the company didn’t adequately live up to its half of a settlement, so she won’t withdraw her complaint to the National Labor Relations Board as agreed, according to Forbes.\r\n",
        "\r\n",
        "Scarlett says that her settlement with Apple required it to post “a company-wide memo clarifying employee rights including discussing pay & working conditions,” “in a prominent and visible location on the People site.” She says that the company did post a notice to its site, but that it was only up during the week that Apple employees were given off for Thanksgiving. “I’d argue all day that 7 days while no one is online for a holiday is absolutely not prominent and visible,” Scarlett tweeted on Thursday.\r\n",
        "\r\n",
        "TheNLRB saysit can reject a withdrawal request made because of a private settlement if it “violates the National Labor Relations Act or Board policy.” Scarlett toldThe Verge that the board initially rejected her request, and sent a list of 22 changes that the board would need Apple to make before it would approve the withdrawal. According to Forbes, one of the requested changes removed wording that would’ve prevented Scarlett from encouraging someone “to file any charge or complaint with any administrative agency or Court against Apple” for a year. According to Scarlett, Apple refused to make those changes.\r\n",
        "\r\n",
        "“I technically could ask for a unilateral withdrawal at this point,” Scarlett said in a message to The Verge, saying that she had been “interested in doing that to avoid witnesses having to give testimony, because realistically the memo is the best outcome we would have gotten from the board.” According to Scarlett, the group of potential witnesses decided it was worth it to continue with the complaint, potentially risking retaliation for testifying, given how Apple handled posting the memo.\r\n",
        "\r\n",
        "Scarlett left the company in November, after filing the complaint that accused the company of engaging “in coercive and suppressive activity that has enabled abuse and harassment of organizers of protected concerted activity.” While at the company, she worked to let employees discuss and gather data about pay equity and was part of #AppleToo, a campaign about the company’s failure to deal with harassment and discrimination.''',\r\n",
        "'onion2' : f'''EAST RUTHERFORD, NJ—Throwing the flag during the annual Army-Navy game after the clearing smoke revealed an obvious illegal hit, Army’s football team received a 15-yard penalty Saturday for drone-striking the kicker. “I don’t know what Army was thinking there—you’re not allowed to drone-strike a defenseless player,” commented CBS play-by-play announcer Brad Nessler, saying that hitting Navy’s kicker with a missile during a field goal attempt and evaporating his body was an easy penalty call for the officials. “You can see that Army’s coach, Jeff Monken, is getting frustrated with his drone operator on the sideline, and it’s understandable. You’ve got to save those drone strikes for ball carriers, and keep the drone strikes to a minimum on special teams. That’s going to give Navy good field position going into the next drive, so we’re going to have to see Army ramp up their M16s on defense if they want to keep this game from getting out of hand early on.” At press time, the referee was standing in the smoldering crater where the kicker’s body once was to overturn the drone-striking penalty after ruling that the offensive line had false-started on the play.''',\r\n",
        "'news_punch2' : f'''Dr. Naomi Wolf, former Clinton admin advisor, has warned that the ‘New World Order’ are lying to keep the public enslaved so they can advance their agenda.\r\n",
        "\r\n",
        "Speaking on Steve Bannon’s War Room, Dr. Wolf declared:\r\n",
        "\r\n",
        "    We’re seeing this state by state.  There’s some kind of contract where governors have to deliver a certain percent of vaccinated in order to get something from pharma or in order to fullfill their contract.  So you can see this structure over and over of, well we have to reach 70% of 80% of vaccinated or you don’t get your rights back.  And, this is not how America works.  I have my rights.  She (New York Governor Hochul) can’t make me…\r\n",
        "\r\n",
        "    …They’re trying to drag us onto their field of rhetoric, and it is a field of rhetoric of lies and it’s built on lies.  And I always think of Goebbels saying if you just tell a big enough lie over and over again people will believe you.  So number one, as I say all the time, everybody agrees, all the data show vaccinated, unvaccinated, that it does not affect transmission.  So all of these tyranical measures are nonsensical because they’re predicated on transmission.\r\n",
        "\r\n",
        "    The other thing I want to say is “We’re not in a pandemic emergency anymore.  It’s not a pandemic.”''',\r\n",
        "'news_punch' : f'''Dr. Anthony Fauci has said that a booster shot that specifically targets the Omicron covid variant may not be needed.\r\n",
        "\r\n",
        "He did say however, that big pharma companies will still develop the variant specific shots.\r\n",
        "\r\n",
        "Fauci told the health news website STAT: “I’m not so sure that we’re going to have to get a variant-specific boost vaccine to get an adequate protection from Omicron….because if you look at protection against variants, it appears to relate to the level of immunity and the breadth of the immunity that any given vaccine can instill on you.”\r\n",
        "\r\n",
        "RT reports: While some experts have expressed concerns that the Omicron variant of the coronavirus is better able to evade the current crop of vaccines, Fauci has continued to place his faith in these shots. So too has Pfizer CEO Albert Bourla, though he has claimed that a fourth dose may be needed to combat the new strain.\r\n",
        "\r\n",
        "“With Omicron we need to wait and see because we have very little information. We may need [the fourth dose] faster,” he told CNBC this week.\r\n",
        "\r\n",
        "While Fauci said that an Omicron-specific booster likely won’t be needed, he did add that drug companies like Pfizer “are going to be making variant-specific boosters.”\r\n",
        "\r\n",
        "Thankfully, the symptoms of the Omicron variant have been described by doctors and officials as mild, and as of Friday, the World Health Organization has not recorded any deaths as a result of the strain.''',\r\n",
        "'news_punch3':f'''The man suing CNN anchor Don Lemon for violently sexually assaulting him has spoken out against the network, warning it is “a predator protecting machine” that must be shut down.\r\n",
        "\r\n",
        "Dustin Hice, who filed a lawsuit against Lemon two years ago, accused the CNN host of violently sexually assaulting him at a New York bar during the summer of 2018.\r\n",
        "\r\n",
        "The case is expected to go to court in 2022.\r\n",
        "\r\n",
        "“They’re a network rife with predators and perverts,” Hice told Fox News.\r\n",
        "\r\n",
        "“Lemon will have to testify under oath in the near future, but it’s good to see that there’s finally some accountability happening.”\r\n",
        "\r\n",
        "Townhall.com reports: Hice explained that he is looking for closure and peace of mind after the incident with Lemon. He alleged that the encounter consisted of Lemon putting his hand down the front of his shorts, “vigorously” rubbing his genitalia and putting the same hand onto Hice’s face while asking a vulgar question.\r\n",
        "\r\n",
        "CNN has yet to discipline Lemon, just like the network failed to do regarding Cuomo until this past week.\r\n",
        "\r\n",
        "“This is who they are. They’re a predator-protecting machine, they slander and smear victims with impunity,” Hice said.  \r\n",
        "\r\n",
        "Hice, who said he refused multiple settlement offers from CNN, believes the network is doing whatever it takes to protect Lemon from liability.\r\n",
        "\r\n",
        "“They’ve tried to grind me down, they’ve attempted to intimidate witnesses in my case, they’ve released confidential information about me in attempt to doxx me. They are complicit. This is who they are,” Hice said.\r\n",
        "\r\n",
        "Lemon’s attorney, Caroline J. Polisi, said Hice’s allegations against her client are “baseless” and “salacious.”\r\n",
        "\r\n",
        "“In response to Mr. Hice’s baseless allegations, I encourage people to review the public filings, which show that Mr. Hice’s claims have been steadily eroding when they have been exposed to the civil litigation process,” Polisi told Fox News Digital. “Mr. Hice’s fanciful and salacious allegations against Mr. Lemon have collapsed of their own weight. Unlike Mr. Hice, Mr. Lemon has litigated, and will continue to litigate this case in the courtroom, not the press. We look forward to the approaching trial so he can finally put this case behind him.”\r\n",
        "\r\n",
        "Hice’s lawsuit, filed in 2019 in Suffolk County Court, claims Lemon “intensely pushed his fingers against Plaintiff’s face under Plaintiff’s nose, forcing Plaintiff’s head thrust backward as Defendant repeatedly asked Plaintiff, ‘Do you like p—y or d–k?'”\r\n",
        "\r\n",
        "The suit also alleges Lemon “continued to shove his fingers into Plaintiff’s face with aggression and hostility” throughout the interaction.\r\n",
        "\r\n",
        "CNN suspended Cuomo Tuesday after the New York state attorney general released documents Monday showing he had used his media contacts to find information about women who accused his brother, former New York Gov. Andrew Cuomo (D), of sexual harassment and was in regular contact with the governor’s top aide about his findings. The network brought in an outside law firm to review the documents.\r\n",
        "\r\n",
        "And on Wednesday, the network was informed that a former colleague of Cuomo’s at ABC News had accused him of sexual misconduct, an incident separate from an allegation from Shelly Ross, who in September wrote a guest essay in The New York Times accusing the anchor of touching her buttocks at a work party in 2005, when the two of them worked at ABC News.\r\n",
        "\r\n",
        "Cuomo was terminated Saturday after “additional information,” not related to his involvement in his brother’s scandal, came to light.\r\n",
        "\r\n",
        "“Chris Cuomo was suspended earlier this week pending further evaluation of new information that came to light about his involvement with his brother’s defense,” CNN said in a statement. “We retained a respected law firm to conduct the review, and have terminated him, effective immediately. While in the process of that review, additional information has come to light. Despite the termination, we will investigate as appropriate.”\r\n",
        "\r\n",
        "Chris Cuomo released a statement of his own following his termination, saying that this “is not how I want my time at CNN to end but I have already told you why and how I helped my brother.”\r\n",
        "\r\n",
        "“So let me now say as disappointing as this is, I could not be more proud of the team at Cuomo Prime Time and the work we did as CNN’s #1 show in the most competitive time slot,” he said. “I owe them all and will miss that group of special people who did really important work.”\r\n",
        "\r\n",
        "Cuomo announced Monday that he will no longer be doing his SiriusXM radio show, Let’s Get After It.''',\r\n",
        "'breitbart' : f'''\r\n",
        "\r\n",
        "WASHINGTON, D.C. — A review of FBI Director James Comey’s professional history and relationships shows that the Obama cabinet leader — now under fire for his handling of the investigation of Hillary Clinton — is deeply entrenched in the big-money cronyism culture of Washington, D.C. His personal and professional relationships — all undisclosed as he announced the Bureau would not prosecute Clinton — reinforce bipartisan concerns that he may have politicized the criminal probe.\r\n",
        "\r\n",
        "These concerns focus on millions of dollars that Comey accepted from a Clinton Foundation defense contractor, Comey’s former membership on a Clinton Foundation corporate partner’s board, and his surprising financial relationship with his brother Peter Comey, who works at the law firm that does the Clinton Foundation’s taxes.\r\n",
        "\r\n",
        "Lockheed Martin\r\n",
        "\r\n",
        "When President Obama nominated Comey to become FBI director in 2013, Comey promised the United States Senate that he would recuse himself on all cases involving former employers.\r\n",
        "\r\n",
        "But Comey earned $6 million in one year alone from Lockheed Martin. Lockheed Martin became a Clinton Foundation donor that very year.\r\n",
        "\r\n",
        "Comey served as deputy attorney general under John Ashcroft for two years of the Bush administration. When he left the Bush administration, he went directly to Lockheed Martin and became vice president, acting as a general counsel.\r\n",
        "\r\n",
        "How much money did James Comey make from Lockheed Martin in his last year with the company, which he left in 2010? More than $6 million in compensation.\r\n",
        "\r\n",
        "Lockheed Martin is a Clinton Foundation donor. The company admitted to becoming a Clinton Global Initiative member in 2010.\r\n",
        "\r\n",
        "According to records, Lockheed Martin is also a member of the American Chamber of Commerce in Egypt, which paid Bill Clinton $250,000 to deliver a speech in 2010.\r\n",
        "\r\n",
        "In 2010, Lockheed Martin won 17 approvals for private contracts from the Hillary Clinton State Department.\r\n",
        "\r\n",
        "HSBC Holdings\r\n",
        "\r\n",
        "In 2013, Comey became a board member, a director, and a Financial System Vulnerabilities Committee member of the London bank HSBC Holdings.\r\n",
        "\r\n",
        "“Mr. Comey’s appointment will be for an initial three-year term which, subject to re-election by shareholders, will expire at the conclusion of the 2016 Annual General Meeting,” according to HSBC company records.\r\n",
        "\r\n",
        "HSBC Holdings and its various philanthropic branches routinely partner with the Clinton Foundation. For instance, HSBC Holdings has partnered with Deutsche Bank through the Clinton Foundation to “retrofit 1,500 to 2,500 housing units, primarily in the low- to moderate-income sector” in “New York City.”\r\n",
        "\r\n",
        "“Retrofitting” refers to a Green initiative to conserve energy in commercial housing units. Clinton Foundation records show that the Foundation projected “$1 billion in financing” for this Green initiative to conserve people’s energy in low-income housing units.\r\n",
        "\r\n",
        "Who Is Peter Comey?\r\n",
        "\r\n",
        "When our source called the Chinatown offices of D.C. law firm DLA Piper and asked for “Peter Comey,” a receptionist immediately put him through to Comey’s direct line. But Peter Comey is not featured on the DLA Piper website.\r\n",
        "\r\n",
        "Peter Comey serves as “Senior Director of Real Estate Operations for the Americas” for DLA Piper. James Comey was not questioned about his relationship with Peter Comey in his confirmation hearing.\r\n",
        "\r\n",
        "DLA Piper is the firm that performed the independent audit of the Clinton Foundation in November during Clinton-World’s first big push to put the email scandal behind them. DLA Piper’s employees taken as a whole represent a major Hillary Clinton 2016 campaign donation bloc and Clinton Foundation donation base.\r\n",
        "\r\n",
        "DLA Piper ranks #5 on Hillary Clinton’s all-time career Top Contributors list, just ahead of Goldman Sachs.\r\n",
        "\r\n",
        "And here is another thing: Peter Comey has a mortgage on his house that is owned by his brother James Comey, the FBI director.\r\n",
        "\r\n",
        "Peter Comey’s financial records, obtained by Breitbart News, show that he bought a $950,000 house in Vienna, Virginia, in June 2008. He needed a $712,500 mortgage from First Savings Mortgage Corporation.\r\n",
        "\r\n",
        "But on January 31, 2011, James Comey and his wife stepped in to become Private Party lenders. They granted a mortgage on the house for $711,000. Financial records suggest that Peter Comey took out two such mortgages from his brother that day.\r\n",
        "\r\n",
        "This financial relationship between the Comey brothers began prior to James Comey’s nomination to become director of the FBI.\r\n",
        "\r\n",
        "DLA Piper did not answer Breitbart News’ question as to whether James Comey and Peter Comey spoke at any point about this mortgage or anything else during the Clinton email investigation.\r\n",
        "\r\n",
        "Peter Comey Re-Designed the FBI Building\r\n",
        "\r\n",
        "FBI Director James Comey grew up in the New Jersey suburbs with his brother Peter. Both Comeys were briefly taken captive in 1977 by the “Ramsey rapist,” but the boys managed to escape through a window in their home, and neither boy was harmed.\r\n",
        "\r\n",
        "James Comey became a prosecutor who worked on the Gambino crime family case. He went on to the Bush administration, a handful of private sector jobs, and then the Obama administration in 2013.\r\n",
        "\r\n",
        "Peter Comey, meanwhile, went into construction.\r\n",
        "\r\n",
        "After getting an MBA in real estate and urban development from George Washington University in 1998, Peter Comey became an executive at a company that re-designed George Washington University between 2004 and 2007 while his brother was in town working for the Bush administration.\r\n",
        "\r\n",
        "In January 2009, at the beginning of the Obama administration, Peter Comey became “a real estate and construction consultant” for Procon Consulting.\r\n",
        "\r\n",
        "Procon Consulting’s client list includes “FBI Headquarters Washington, DC.”\r\n",
        "\r\n",
        "So what did Procon Consulting do for FBI Headquarters? Quite a bit, apparently. According to the firm’s records:\r\n",
        "\r\n",
        "    Procon provided strategic project management for the consolidation of over 11,000 FBI personnel into one, high security, facility.\r\n",
        "\r\n",
        "    Since 1972 the Federal Bureau of Investigation has had its headquarters in a purpose built 2.1 million square foot building on Pennsylvania Avenue. Having become functionally obsolete and in need of major repairs, GSA and the FBI were considering ways to meet the space needs required to maintain the Bureau’s mission and consolidate over 11,000 personnel.\r\n",
        "\r\n",
        "    Procon assisted GSA in assessing the FBI’s space needs and options for fulfilling those needs. Services provided included project management related to site evaluations, budgeting, due diligence, and the development of procurement and funding strategies.\r\n",
        "\r\n",
        "Those “funding strategies” included talking to “stakeholders”: “Worked with stakeholders and key leadership to identify strategic objectives, goals and long range plans for capital and real estate projects.”\r\n",
        "\r\n",
        "Procon Consulting obtained its contract for FBI Headquarters prior to James Comey’s nomination to serve as director of the FBI.\r\n",
        "\r\n",
        "In June 2011, Peter Comey left Procon Consulting to become “Senior Director of Real Estate Operations for the Americas” for DLA Piper.\r\n",
        "\r\n",
        "Peter Comey has generated some controversy in that role. According to Law360 in May 2013 (the same month that James Comey was confirmed as someone being considered by Obama to become FBI director):\r\n",
        "\r\n",
        "    Two real estate services businesses filed a $10 million suit against the law firm Monday alleging it stiffed them on as much as $760,000 of work done at DLA Piper’s Chicago office and improperly gave proprietary information to a competitor.\r\n",
        "\r\n",
        "    ….\r\n",
        "\r\n",
        "    The plaintiffs take particular aim at Peter Comey, DLA Piper’s senior director of real estate operations. Leasecorp and SpaceLogik include several emails in the complaint that are purportedly from DLA Piper senior real estate partners Jay Epstein and Rich Klawiter and are sharply critical of Comey’s handling of the matter. In one email, Epstein wrote that “it’s an embarrassment for the firm to be treating someone who we are working with like this.”\r\n",
        "\r\n",
        "    In another email allegedly from Klawiter on Feb. 20, the DLA Piper partner informed Leasecorp President Michael Walker, a principal for both plaintiffs, that Comey had sent him and Epstein an email claiming that the real estate services firms were behind on their contractual obligations.\r\n",
        "\r\n",
        "    “I just received an email from Peter (Jay was also a recipient) that is so inflammatory I can’t even send it or you’ll hit the roof,” Klawiter said in the email, according to the complaint. “This is not going to end well.”\r\n",
        "\r\n",
        "''',\r\n",
        "'greatgameindia' : f'''Last year a mysterious shipment was caught smuggling Coronavirus from Canada. It was traced to Chinese agents working at a Canadian lab. Subsequent investigation by GreatGameIndia linked the agents to Chinese Biological Warfare Program from where the virus is suspected to have leaked causing the Wuhan Coronavirus outbreak.\r\n",
        "\r\n",
        "Note: BuzzFeed Reporter Who Attacked GreatGameIndia’s Coronavirus Bioweapon Story, Fired For Plagiarism\r\n",
        "\r\n",
        "The findings of this investigation has been corroborated by none other than the Bioweapons expert Dr. Francis Boyle who drafted the Biological Weapons Convention Act followed by many nations. The report has caused a major international controversy and is suppressed actively by a section of mainstream media.\r\n",
        "\r\n",
        "Infographic based on this report – The Secret History Of Coronavirus\r\n",
        "\r\n",
        "Coronavirus Bioweapon\r\n",
        "Coronavirus Bioweapon – How Chinese agents stole Coronavirus from Canada and weaponized it into a Bioweapon\r\n",
        "The Saudi SARS Sample\r\n",
        "\r\n",
        "On June 13, 2012 a 60-year-old Saudi man was admitted to a private hospital in Jeddah, Saudi Arabia, with a 7-day history of fever, cough, expectoration, and shortness of breath. He had no history of cardiopulmonary or renal disease, was receiving no long-term medications, and did not smoke.\r\n",
        "\r\n",
        "Egyptian virologist Dr. Ali Mohamed Zaki isolated and identified a previously unknown coronavirus from his lungs. After routine diagnostics failed to identify the causative agent, Zaki contacted Ron Fouchier, a leading virologist at the Erasmus Medical Center (EMC) in Rotterdam, the Netherlands, for advice. \r\n",
        "Abnormalities on Chest Imaging of the Saudi patient infected with Coronavirus\r\n",
        "Abnormalities on Chest Imaging of the Saudi patient infected with Coronavirus. Shown are chest radiographs of the patient on the day of admission (Panel A) and 2 days later (Panel B) and computed tomography (CT) 4 days after admission (Panel C).\r\n",
        "\r\n",
        "Fouchier sequenced the virus from a sample sent by Zaki. Fouchier used a broad-spectrum “pan-coronavirus” real-time polymerase chain reaction (RT-PCR) method to test for distinguishing features of a number of known coronaviruses known to infect humans.''',\r\n",
        "'tatum_reort' : f'''Evidence is mounting that the FBI was involved in planning and executing the January 6 Capitol event after a report dropped Monday night silently from Revolver News. The moment January 6 happened, the suspicion that this wasn’t coming from the MAGA movement was immediate.\r\n",
        "\r\n",
        "Conservatives immediately saw this for what it was and refused to believe that MAGA people did anything but protest peacefully. Revolver says the evidence points to the FBI as a major contributing factor if not the culprit behind the January 6 psyop. \r\n",
        "\r\n",
        "The report tackled three questions about January 6 (1/6):\r\n",
        "\r\n",
        "    “In the year leading up to 1/6 and during 1/6 itself, to what extent were the three primary militia groups (the Oath Keepers, the Proud Boys, and the Three Percenters) that the FBI, DOJ, Pentagon and network news have labeled most responsible for planning and executing a Capitol attack on 1/6 infiltrated by agencies of the federal government, or informants of said agencies?\r\n",
        "    Exactly how many federal undercover agents or confidential informants were present at the Capitol or in the Capitol during the infamous “siege” and what roles did they play (merely passive informants or active instigators)?\r\n",
        "    Finally, of all of the unindicted co-conspirators referenced in the charging documents of those indicted for crimes on 1/6, how many worked as a confidential informant or as an undercover operative for the federal government (FBI, Army Counterintelligence, etc.)?”\r\n",
        "\r\n",
        "First, Revolver News broke the “siege” participants into two categories based on the level of crimes committed. The report gathered them into “Mostly Harmless Tourists” and “Unindicted Co-Conspirators Who Belonged To Any Of The Big Three’ Militia Groups.’ ”\r\n",
        "\r\n",
        "The first category, “most harmless tourists,” encompasses most of those arrested after January 6. Julie Kelly published a gripping article that showcased letters from the political prisoners. Jonathan Mellis, son of a decorated Vietnam vet, was denied bail by the same judge that refused to drop the charges against Gen. Flynn.\r\n",
        "\r\n",
        "Mellis wrote in part: \r\n",
        "\r\n",
        "“We are charged with every possible offense and held in the DC jail on solitary [sic] confinement and treated inhumanely. For example, a correctional officer from a different pod came to C2B screaming at us late at night on 6/1/21 because we had just sang ‘God Bless America’ [sic] from behind our locked doors like we do every night. Being as we are on lockdown 22 hours a day it’s nice to keep morale up through patriotism. When [name omitted by American Greatness], my next door [sic] neighbor, informed the officer that we were just singing ‘God Bless America’ the officer responded by yelling, ‘F*** [sic] America!’\r\n",
        "\r\n",
        "I am concerned for the safety of myself and my fellow Capitol rioters here in the DC jail. We are locked down all day and threatened with violence regularly. We all know that getting our hands tied together and being beaten is something the DC jail officers have already done to Capitol rioters in this pod.\r\n",
        "\r\n",
        "Solitary Confinement and beatings. That is our reality. When will the inhumane treatment end? I just want to let everyone know the reality of how we are treated in this place. Left wing [sic] rioters are not even held in jail. Much less subjected to the harsh and inhumane treatment my fellow Capitol rioters and I have survived under so far this year.”\r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        "According to the Revolver report, the second group, unindicted co-conspirators, “closely align” with the “violent insurrectionist” caricature that we hear about in the media and that the government claims to be targeting with “aggressive prosecutions.” The assertion here is that federal informants or undercover operatives infiltrated the militia groups and instigated the violence.\r\n",
        "\r\n",
        "The report stated, “If it turns out that extraordinary percentage of the members of these groups involved in planning and executing the Capitol Siege were federal informants or undercover operatives, the implications would be nothing short of staggering.”\r\n",
        "\r\n",
        "This would imply that the federal government knew about the attacks and did nothing to thwart them because the federal agencies, tasked with protecting us, “were active instigators in the most egregious and spectacular aspects of 1/6, amounting to a monumental entrapment scheme used as a pretext to imprison otherwise harmless protestors at the Capitol – and in a much larger sense used to frame the entire MAGA movement as potential domestic terrorists.”\r\n",
        "\r\n",
        "The proof the FBI was actively using these practices “we need only go back a few months prior to 1/6 – to the so-called ‘Whitmer Kidnapping Plot.’ “Remember the kidnapping plot against Michigan Governor Whitmer? The question I had at the time was: “Why is the FBI able to track these men down organizing across state lines, and yet ANTIFA/BLM rioters are on video in multiple different states telling you they are going to burn cities to the ground, and they aren’t capable of finding the leader?”\r\n",
        "\r\n",
        "The answer is now more clear. Revolver reports that we now know “of the 14 individuals who allegedly plotted the “kidnapping” and overthrow of the state government, at least five were undercover agents and federal informants.” The FBI even used the same milia group, the “Three Percenters,” for Gov. Whitmer and January 6.\r\n",
        "\r\n",
        "And on top of that, “the director of the Detroit FBI Field Office, who oversaw the infiltration operation of the Michigan Plot, was subsequently granted a highly coincidental promotion to the DC office, where he is now the lead FBI agent for all 1/6 cases.”\r\n",
        "\r\n",
        "On Tucker Carlson last night, Darren Beattie spoke about the Revolver News report, and a stunned Carlson asked him: ” After seeing all of this, you have to ask yourself: Does the national security apparatus do anything but conspire against the American people?”\r\n",
        "\r\n",
        "The answer is a simple but firm no. It’s time to tear them down to the studs and bring them back under our control.''',\r\n",
        "'notrealnews' : f'''As the world is gearing up for the coronavirus pandemic, cities are vowing to not let the virus move in to prevent the worst. During the Great Influenza Pandemic of 1918, World War I had already begun. Both events led to massive absenteeism, reducing production of pharmaceuticals for public health and sanitary purposes, and the need for screening for potential pandemic viruses, required by international treaties.\r\n",
        "\r\n",
        "Public health is more fragile than ever today, and still heavily dependent on drug manufacturing capacity. Access to funding for pharmaceutical research and development, and basic tests, are both harder and harder.\r\n",
        "\r\n",
        "Each year, the National Institutes of Health (NIH) grants millions to industries on the hopes of developing potential treatments, even though only about 15-20% of applications meet the criteria for granting a grant. The stakes are quite high in terms of life-saving products, but the uncertainty of funding can be paralyzing for many.\r\n",
        "\r\n",
        "Five years ago, would it have been easy to imagine the world’s financial crisis in the context of pandemics. This time, however, the financial crisis was intertwined with the pandemic, rendering it even harder for hardtech and moonshots to get funding for product development or expansion.\r\n",
        "\r\n",
        "Of course, modern technology makes pandemics a bit easier to forecast. Companies in the public health and pharmaceutical industry, faced with fewer options to invest in, have shifted from good old single-drug testing to mapping infectious diseases along the structural and molecular networks required to kill or control them with greater precision. New technology, and specifically, the targeted surveillance process used in collecting data to guide policy, may make our pandemics better.\r\n",
        "\r\n",
        "As a researcher at Columbia University’s Center for the Study of Drug Development, I’ve experienced how hard it is to support new product development that is based around scalable or cheap manufacturing processes. The decrease in funding for the public health and pharmaceutical industries has further muted my colleagues’ enthusiasm for new platforms and technologies. The thought of spending millions to gain a competitive advantage over more ambitious competitors, despite the potential advantages, simply seems to be too risky.\r\n",
        "\r\n",
        "After years of incubating, funding and working on multiple platforms, we have most of what we need. However, we can’t do it on our own. The public health and pharmaceutical industries have to figure out how to find global market-share for products that would benefit both industry and the rest of the world, including our food system.\r\n",
        "\r\n",
        "The tenacity of the software industry, however, may provide some hope. Fundraising for hardtech, or hardtech-based moonshots, will be arduous. Cremades' favorite hardtech idea will always be consumer autonomy. Things that need to know the user to start, instead of the user having to do things that they don’t need.\r\n",
        "\r\n",
        "Would funding of consumer autonomy be possible even when the world didn’t have a major pandemic? For sure, but there’s a limit to the amount of time you can spend solving problems that also concern large stakeholders (the public, the tech industry, and the industry itself). The global threat perception surrounding the pandemic has made funding harder than ever.\r\n",
        "\r\n",
        "While finding product market fit after the coronavirus pandemic is going to be hard because of how huge the economic downturn is, I do see several opportunities.\r\n",
        "\r\n",
        "Public engagement with disease research and surveillance may encourage the public to adopt new products and systems, in the same way it’s prompted other industries to get active in the innovation game.'''\r\n",
        "}"
      ],
      "outputs": [],
      "execution_count": 169,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639365911742
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k,v in real_world.items():\r\n",
        "    print(f'article:{k}, result:{convert_article(v)}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "article:beaver, result:[[0.00481387]]\narticle:cnn, result:[[0.00828139]]\narticle:cnn2, result:[[0.00362464]]\narticle:gwpundit, result:[[0.00228828]]\narticle:onion, result:[[0.02415777]]\narticle:the_verge, result:[[0.00774566]]\narticle:onion2, result:[[0.00540014]]\narticle:news_punch2, result:[[0.01684748]]\narticle:news_punch, result:[[0.00504156]]\narticle:news_punch3, result:[[0.0159876]]\narticle:breitbart, result:[[0.03910823]]\narticle:greatgameindia, result:[[0.00456028]]\narticle:tatum_reort, result:[[0.00888953]]\narticle:notrealnews, result:[[0.007694]]\n"
        }
      ],
      "execution_count": 171,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639365956433
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in fake_1:\r\n",
        "    test = convert_article(i)\r\n",
        "    print(test)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[[0.9999925]]\n[[0.99967957]]\n[[0.999969]]\n[[0.99999]]\n[[0.99999416]]\n[[0.999724]]\n[[0.99999416]]\n[[0.99999464]]\n[[0.9997795]]\n[[0.9998901]]\n[[0.9999939]]\n[[0.9999932]]\n[[0.9999932]]\n[[0.9999939]]\n[[0.9999943]]\n[[0.9999945]]\n[[0.9999926]]\n[[0.99999356]]\n[[0.99999464]]\n[[0.9999944]]\n[[0.9999933]]\n[[0.99999285]]\n[[0.9999794]]\n[[0.9999943]]\n[[0.99999416]]\n[[0.9999939]]\n[[0.9999939]]\n[[0.9999448]]\n[[0.9999925]]\n[[0.99999106]]\n[[0.99999404]]\n[[0.9999949]]\n[[0.9999939]]\n[[0.99978477]]\n[[0.9999926]]\n[[0.99999464]]\n[[0.9999945]]\n[[0.99999297]]\n[[0.99999404]]\n[[0.99988484]]\n[[0.9999937]]\n[[0.9999924]]\n[[0.99999356]]\n[[0.9999937]]\n[[0.99999285]]\n[[0.9999943]]\n[[0.9999939]]\n[[0.99999404]]\n[[0.99999475]]\n[[0.9999937]]\n[[0.9999949]]\n[[0.9999926]]\n[[0.9999949]]\n[[0.9999937]]\n[[0.9999831]]\n[[0.9999943]]\n[[0.9999939]]\n[[0.9999937]]\n[[0.9999937]]\n[[0.99999225]]\n[[0.9999536]]\n[[0.9999949]]\n[[0.9999937]]\n[[0.9999949]]\n[[0.9999949]]\n[[0.9999949]]\n[[0.99999213]]\n[[0.99997175]]\n[[0.99999475]]\n[[0.99998975]]\n[[0.9999949]]\n[[0.999995]]\n[[0.99999416]]\n[[0.99999475]]\n[[0.9999949]]\n[[0.9999949]]\n[[0.9999949]]\n[[0.99999464]]\n[[0.9999949]]\n[[0.999995]]\n[[0.99999475]]\n[[0.999995]]\n[[0.9999937]]\n[[0.99999475]]\n[[0.9999939]]\n[[0.9999814]]\n[[0.9999949]]\n[[0.99997437]]\n[[0.9999944]]\n[[0.99999475]]\n[[0.9999943]]\n[[0.9998901]]\n[[0.999995]]\n[[0.99999416]]\n[[0.9999933]]\n[[0.9999939]]\n[[0.9999937]]\n[[0.99999344]]\n[[0.9999949]]\n[[0.9999938]]\n"
        }
      ],
      "execution_count": 70,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639345499054
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### So... our model didnt do well against real world data we went out and find, it was able to classify real news well but not fake news we went out and found"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset = pd.read_csv('./data/fake_or_real_news.csv')"
      ],
      "outputs": [],
      "execution_count": 137,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639360448030
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real = new_dataset[new_dataset['label']=='REAL']\r\n",
        "fake = new_dataset[new_dataset['label']=='FAKE']"
      ],
      "outputs": [],
      "execution_count": 139,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639360590366
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake_texts = fake.text.tolist()\r\n",
        "real_texts = real.text.tolist()"
      ],
      "outputs": [],
      "execution_count": 141,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639360672099
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real_results = [(convert_article(x)>0.5).astype(\"int32\")  for x in real_texts[0:1000] ]\r\n",
        "fake_results = [(convert_article(x) > 0.5).astype(\"int32\")  for x in fake_texts[0:1000] ]\r\n"
      ],
      "outputs": [],
      "execution_count": 162,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639365623376
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "real['output'] = 0\r\n",
        "fake['output'] = 1\r\n",
        "\r\n",
        "fake_pred = fake.output.tolist()\r\n",
        "real_pred = real.output.tolist()\r\n",
        "real_results = np.concatenate(real_results,axis=1)[0]\r\n",
        "fake_results = np.concatenate(fake_results,axis=1)[0]\r\n"
      ],
      "outputs": [],
      "execution_count": 163,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639365697881
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "#real_results\r\n",
        "print(accuracy_score(fake_results,fake_pred[:1000]))\r\n",
        "print(accuracy_score(real_results,real_pred[:1000]))\r\n",
        "#print(accuracy_score(fake_results,fake_pred))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0.005\n0.987\n"
        }
      ],
      "execution_count": 172,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639366684861
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "2174f4ae4218edf439e1893aa1a6da922aedf8fa916257c8eab7e59a849160d6"
    },
    "kernelspec": {
      "name": "azureml_py38_tensorflow",
      "language": "python",
      "display_name": "Python 3.8 - Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "kernel_info": {
      "name": "azureml_py38_tensorflow"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}